{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Analysis of the Influencers:\n",
    "# 2. Sentiment Analysis of the Influencers: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import time\n",
    "from datetime import datetime, timezone\n",
    "# import seaborn as sns\n",
    "from os import path, makedirs # fetch path and makedirs function from os file\n",
    "import csv # fetch csv file\n",
    "from glob import glob # fetching glob function only from the glob lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keys from the config file\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Twitter API Keys\n",
    "# consumer_key = 'Your Key'\n",
    "# consumer_secret = 'Your Key'\n",
    "# access_token = 'Your Key'\n",
    "# access_token_secret = 'Your Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and read csv file containing the details of the Influencers \n",
    "influencer_data_load = \"RawData/SentimentInfluencerInputData.csv\"\n",
    "influencer_data_read = pd.read_csv(influencer_data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in Influencers_DF.iterrows():\n",
    "Data_Influencers_DF = influencer_data_read\n",
    "Not_Found = 0\n",
    "\n",
    "#SS - define variable for holding tweets for influencer\n",
    "\n",
    "all_tweet_listing = []\n",
    "\n",
    "print(\"-----------Start extraction!!!-----------\")\n",
    "\n",
    "for index, row in Data_Influencers_DF.iterrows():\n",
    "    target_user = row[\"Twitter_Handle\"]\n",
    "    Genre =  row[\"Genre\"]\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        #SS - retrieve top 200 tweets for influencer\n",
    "        \n",
    "        public_tweets = api.user_timeline(target_user, count=200, result_type=\"recent\")\n",
    "\n",
    "        #SS - write to all_tweet_listing\n",
    "\n",
    "        for tweet in public_tweets:\n",
    "            \n",
    "            Date = datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S %z %Y').strftime('%m/%d/%Y')\n",
    "\n",
    "            all_tweet_listing.append({\"Influencer\":target_user,\n",
    "                               \"Date\": Date,\n",
    "                               \"Genre\":Genre,\n",
    "                               \"Tweet\":tweet[\"text\"]})\n",
    "    \n",
    "        user_account = api.get_user(target_user)\n",
    "        \n",
    "        user_geo_enabled = user_account[\"geo_enabled\"]\n",
    "        \n",
    "        if (user_geo_enabled == True):\n",
    "            Data_Influencers_DF.at[index, \"Loc\"] = user_account[\"location\"]\n",
    "        else:\n",
    "            Data_Influencers_DF.at[index, \"Loc\"] = 'NA'\n",
    "\n",
    "        if (user_account[\"lang\"] == 'en'):\n",
    "            Data_Influencers_DF.at[index, \"Lang\"] = 'Eng'\n",
    "        else:\n",
    "            Data_Influencers_DF.at[index, \"Lang\"] = 'NA'\n",
    "        \n",
    "        Data_Influencers_DF.at[index, \"Created On\"] = datetime.strptime(user_account['created_at'],'%a %b %d %H:%M:%S %z %Y').strftime('%m/%d/%Y')\n",
    "        \n",
    "        Data_Influencers_DF.at[index, \"Age Of Account\"] = (datetime.now(timezone.utc) - datetime.strptime(user_account['created_at'],'%a %b %d %H:%M:%S %z %Y')).days\n",
    "        \n",
    "        \n",
    "       #  Data_Influencers_DF.at[index, \"Real Name\"] = user_real_name\n",
    "        Data_Influencers_DF.at[index, \"Tweets\"] = user_account[\"statuses_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Followers\"] = user_account[\"followers_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Following\"] = user_account[\"friends_count\"]\n",
    "        Data_Influencers_DF.at[index, \"Favorites Count\"] = user_account[\"favourites_count\"]\n",
    "        \n",
    "              \n",
    "    \n",
    "    except tweepy.TweepError as e:\n",
    "        Not_Found = Not_Found + 1\n",
    "        print(f\"exception for {row['Twitter_Handle']}: {e}\")\n",
    "\n",
    "print(\"----------- Extraction Complete !!!-----------\")        \n",
    "print(Not_Found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SS -translate dict to a dataframe\n",
    "tweet_listing_pd = pd.DataFrame.from_dict(all_tweet_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SS -stats for tweet listing for influencers. PLEASE DON'T REMOVE. Required to quantify digital footprint!\n",
    "tweet_listing_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SS -top 1000 key words from Influencer tweets\n",
    "\n",
    "Top_1000 = pd.Series(' '.join(tweet_listing_pd['Tweet']).lower().split()).value_counts()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_1000.to_csv(\"RawData/Top_1000_keywords.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SS - Write to CSV for analysis\n",
    "tweet_listing_pd.to_csv(\"RawData/TweetListings.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SS - define target tags for social and entertainment\n",
    "\n",
    "# social_target_tags = [\"#FamiliesBelongTogetherMarch\",\"#gun\",\"gun\",\"shooting\",\"gun-control\",\"election\",\"#metoo\",\"metoo\",\"FamiliesBelongTogetherMarch\",\"PrideMonth\",\"#PrideMonth\",\"FamiliesBelongTogether\",\"ChildreninCages\",\"UniteTheFamilies\",\"WeCare\"]\n",
    "\n",
    "# entertainment_target_tags = [\"#SocialMediaDay\",\"SocialMediaDay\",\"WorldCup\",\"#WorldCup\",\"#fifa\",\"fifa\", \"#worldcup2018russia\",\"#PostASongLyricYouLove\"]\n",
    "\n",
    "# #SS - define lists to hold tweets based on tags\n",
    "\n",
    "# social_tweet_list_dict = []\n",
    "\n",
    "# entertainment_tweet_list_dict = []\n",
    "\n",
    "# for index, row in tweet_listing_pd.iterrows():\n",
    "    \n",
    "#     tweet_listing_filtered = [tweet_listing_pd[tweet_listing_pd['Tweet'].str.contains(x)] for x in target_tags]\n",
    "    \n",
    "#     for tweet_list in tweet_listing_filtered:\n",
    "#         Date = tweet_list[\"Date\"]\n",
    "#         Genre = tweet_list[\"Genre\"]\n",
    "#         Influencer = tweet_list[\"Influencer\"]\n",
    "#         Tweet = tweet_list[\"Tweet\"]\n",
    "#         tweet_list_dict.append({\n",
    "#             \"Data\" : Data,\n",
    "#             \"Genre\":Genre,\n",
    "#             \"Influencer\": Influencer,\n",
    "#             \"Tweet\" : Tweet\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values.\n",
    "Data_Influencers_DF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grouped on Genre \n",
    "Data_Influencers_DF['Average Tweets'] = Data_Influencers_DF['Tweets']\n",
    "AggregatedGenre= Data_Influencers_DF.groupby([\"Genre\"]).agg({'Genre': 'count', 'Tweets': 'sum', 'Followers': 'sum','Average Tweets':'mean','Age Of Account':'mean'})\n",
    "AggregatedGenre\n",
    "AggregatedGenre.sort_values(['Followers'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting on Average Tweets and grouped on Genere\n",
    "AggregatedGenre.sort_values(['Average Tweets'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People who are top ten Influencer who tweet more\n",
    "top_ten_twitters = Data_Influencers_DF.sort_values(['Tweets'],ascending=False).head(10)\n",
    "top_ten_twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top ten Influencer who who have more Followers\n",
    "top_ten_influencer = Data_Influencers_DF.sort_values(['Followers'],ascending=False).head(10)\n",
    "top_ten_influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still Working test cell\n",
    "# to find the handle of followers of the top most \n",
    "# active Influencer so that we can send the tweet through a bot.\n",
    "# top_ten_twitters.head(1)['Twitter_Handle'].map(lambda x: x.lstrip('@'))\n",
    "# import time\n",
    "# ids = []\n",
    "# for page in tweepy.Cursor(api.followers_ids, top_ten_twitters.head(1)['Twitter_Handle'].map(lambda x: x.lstrip('@'))).pages():\n",
    "#     ids.extend(page)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment Analysis of the Influencers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Influencers = influencer_data_read\n",
    "# s = Influencers.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the first 100 tweets of the Influencers\n",
    "print(\"-----------Start extraction of the tweets posted by the Influencers!!!-----------\")\n",
    "Influencers = []\n",
    "Influencers = top_ten_twitters\n",
    "# Influencers = influencer_data_read\n",
    "# Influencers_th = Influencers.iloc[:,0]\n",
    "# # Array to hold the sentiments\n",
    "# Tweet_array = []\n",
    "Sentiment_array = []\n",
    "\n",
    "# for user in Influencers[0]:\n",
    "# for user in Influencers_th:\n",
    "for user in Influencers:\n",
    "    # Set the tweet count to 100\n",
    "    tweet_count = 100\n",
    "    print(\"Extracting tweets from %s\"%user)\n",
    "    \n",
    "    # Extract tweets up to 5 pages\n",
    "    for x in range(1):\n",
    "        influencer_tweets = api.user_timeline(user,page = 1)       \n",
    "        \n",
    "#         # For each tweet in a bunch of public tweets\n",
    "for tweet in influencer_tweets:\n",
    "            \n",
    "            #Calculate the compound, positive, negative and neutral values of each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "            \n",
    "            # Save the Tweets in an array as a dictionery item \n",
    "            Sentiment_array.append({\"Influencers\" : user,\n",
    "                                    \"Tweet Text\" : tweet[\"text\"],\n",
    "                                    \"Compound\" : compound,\n",
    "                                    \"Positive\" : pos,\n",
    "                                    \"Negative\" : neg,\n",
    "                                    \"Neutral\" : neu,\n",
    "                                    \"Date\" : tweet[\"created_at\"],\n",
    "                                    \"Tweets Ago\" : tweet_count\n",
    "                                   })\n",
    "            \n",
    "            #Decrease count of tweet by 1 in the reverse order\n",
    "            tweet_count -= 1\n",
    "\n",
    "print(\"-----------End of Extraction of Tweets !!!-----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataframe from the Dictionery item of the Sentiment Array\n",
    "# Sentiment_DF = pd.DataFrame.from_dict(Sentiment_array)\n",
    "\n",
    "# # Remove the '@' from the 'influence' column in the data frame\n",
    "# Sentiment_DF[\"Influencers\"] = Sentiment_DF[\"Influencers\"].map(lambda x: x.lstrip('@'))\n",
    "\n",
    "# # Re_arrang the columns and save into a CSV file\n",
    "# Sentiment_DF = Sentiment_DF[[\"Influencers\", \"Date\", \"Tweet Text\"\n",
    "#                              , \"Compound\", \"Positive\", \"Negative\"\n",
    "#                              , \"Neutral\", \"Tweets Ago\"\n",
    "#                             ]]\n",
    "\n",
    "# # Store output in a .CSV File\n",
    "# Sentiment_DF.to_csv(\"influencer_tweets_Analysis.csv\")\n",
    "\n",
    "# # Sentiment_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the mean for each Influencers & store into a dataframe\n",
    "# Influencers_Comp_Mean = Sentiment_DF.groupby(\"Influencers\").mean()[\"Compound\"].to_frame()\n",
    "\n",
    "# #Reset the index \n",
    "# Influencers_Comp_Mean.reset_index(inplace=True)\n",
    "\n",
    "# Influencers_Comp_Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the values for x_axis & y_axis\n",
    "# x_axis = Influencers_Comp_Mean.index.values\n",
    "# y_axis = Influencers_Comp_Mean[\"Compound\"]\n",
    "# X_Label = [\"@Oprah\",\"@KimKardashian\",\"@realDonaldTrump\",\"@justinbieber\",\"@KylieJenner\"]\n",
    "\n",
    "# # Intialize the plots. \n",
    "# fig,ax = plt.subplots()#  function that returns a tuple containing a figure and axes object(s)\n",
    "\n",
    "# #Set the plot and assign the values like colors etc\n",
    "# bars = ax.bar(x_axis,y_axis\n",
    "#               , align = \"edge\"\n",
    "#               , width = 1\n",
    "#               , linewidth = 1\n",
    "#               , edgecolor = 'black'\n",
    "#               , color = [\"yellow\",\"lime\",\"red\",\"orange\",\"pink\"]\n",
    "#              )\n",
    "\n",
    "# # Set the tick(s) of the bar graph\n",
    "# tick_locations = [value + 0.5 for value in range(len(x_axis))]\n",
    "# plt.xticks(tick_locations,X_Label,rotation='vertical')\n",
    "\n",
    "# # If value is positive then put True in the Summary else place False\n",
    "# Influencers_Comp_Mean[\"Positive\"] = Influencers_Comp_Mean[\"Compound\"] > 0\n",
    "\n",
    "# # Assign the height based on positive value after allocating True / false value\n",
    "# height = Influencers_Comp_Mean.Positive.map({True: 0.03 , False: -0.03})\n",
    "\n",
    "# # # Set the value on labels on the bars\n",
    "# for bar in bars:\n",
    "#     ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + height[bars.index(bar)]\n",
    "#             , round(Influencers_Comp_Mean[\"Compound\"][bars.index(bar)],3)\n",
    "#             , ha = 'center'\n",
    "#             , va = 'bottom'\n",
    "#             )\n",
    "\n",
    "# # Set the x_axis limits\n",
    "# ax.set_xlim(0, len(x_axis))\n",
    "\n",
    "# # Dynamically set the y_axis limits by finding the max & min value of y-axis\n",
    "# ax.set_ylim(min(y_axis)-0.1, max(y_axis) + 0.1)\n",
    "\n",
    "# # Set a horizontal line at y = 0\n",
    "# plt.hlines(0,0,len(x_axis))\n",
    "\n",
    "# # Title of the graph\n",
    "# ax.set_title(\"Sentiments on Twitter of Influencers (%s)\" % (time.strftime(\"%x\")), fontsize=16)\n",
    "\n",
    "# # Setting the y_axis label\n",
    "# ax.set_ylabel(\"Polarity on Twitter \", fontsize=14)\n",
    "\n",
    "# # # Setting the x_axis label\n",
    "# ax.set_xlabel(\"The Influencers\", fontsize=14)\n",
    "  \n",
    "# # Saving the graph\n",
    "# plt.savefig(\"The Influencer Twitter Sentiment .png\",bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an array of Influencers Houses with the unique function in the data frame\n",
    "# Influencers_array = Sentiment_DF[\"Influencers\"].unique()\n",
    "# Influencers_array\n",
    "\n",
    "# # #Plotting the graph for each influencer\n",
    "# for influencer in Influencers_array:\n",
    "# # Creating a temporary data frame to store for only one influencer at a time\n",
    "#         Temp_DF = Sentiment_DF[Sentiment_DF[\"influencer\"] == influencer]\n",
    "        \n",
    "#         Sentiment_DF['influencer'] = Sentiment_DF['influencer'].map(lambda x: x.lstrip('@'))\n",
    "# #Temp_DF\n",
    "    \n",
    "#         plt.scatter(Temp_DF[\"Tweets Ago\"],Temp_DF[\"Compound\"]\n",
    "#                  , marker = \"o\", linewidth = 0, alpha = 0.8, label = Influencers\n",
    "#                  , facecolors = Temp_DF.influencer.map({\"@Oprah\": \"blue\"\n",
    "#                                                    , \"@KimKardashian\" : \"lime\"\n",
    "#                                                    , \"@realDonaldTrump\": 'indigo'\n",
    "#                                                    , \"@justinbieber\":\"fuchsia\"\n",
    "#                                                    , \"@KylieJenner\":\"gold\"\n",
    "#                                                   })\n",
    "#                 )\n",
    "\n",
    "# # # Set the legend \n",
    "# plt.legend(bbox_to_anchor = (1,1), title=\"The Influencers\", loc='best')\n",
    "\n",
    "# # # Set the labels of x_axis, y_axis & title \n",
    "# plt.xlabel(\"Tweets Ago\", fontsize=12)\n",
    "# plt.ylabel(\"Tweet Polarity\", fontsize=12)\n",
    "# plt.title(\"Sentiment Analysis of The Influencers Tweets (%s)\" % (time.strftime(\"%x\")), fontsize=16)\n",
    "\n",
    "# # #Set the limite of  x_axis and y_axis\n",
    "# plt.xlim(0, 101)\n",
    "# plt.ylim(-1,1)\n",
    "\n",
    "# # # Set the grid\n",
    "# plt.grid(True)\n",
    "\n",
    "# filePath = 'Images'\n",
    "# if not path.exists(filePath):\n",
    "#     makedirs(filePath)\n",
    "\n",
    "# # Save the result to a .png file\n",
    "# plt.savefig(\"Sentiment Analysis of Influencers Tweets.png\",bbox_inches='tight')\n",
    "# # plt.savefig(\"Sentiment Analysis of The influencer's Tweets.png\",bbox_inches='tight')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version: 2.0\n",
    "# Date: Sunday 7/1\n",
    "# Time: 03:40 PM\n",
    "# Functionalities: \n",
    "# A) Data Analysis\n",
    "#     1. Created dataframe.\n",
    "#     2. Sorting\n",
    "# B) Sentiment Analysis\n",
    "\n",
    "\n",
    "# Pending items:\n",
    "# Data Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
